import streamlit as st
import pandas as pd
import numpy as np
import os
import pickle
from datetime import datetime, timedelta
import plotly.express as px
from tflite_utils import load_tflite_model, tflite_predict
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.impute import SimpleImputer

## Helpers for model inference and data loading
@st.cache_resource
def load_artifacts():
    # Directory of this script
    base_dir = os.path.dirname(__file__)
    # Artifact paths
    model_path = os.path.join(base_dir, 'crime_prediction_model.tflite')
    
    # Load TFLite model
    model = load_tflite_model(model_path)
    
    # Load data to create preprocessors
    data_path = os.path.join(base_dir, 'combined_data.csv')
    df = pd.read_csv(data_path)
    
    # Create Label Encoder for offense categories
    le = LabelEncoder()
    le.fit(df['offense_category_name'].astype(str))
    
    # Create StandardScaler for environmental features only
    scaler = StandardScaler()
    env_features = ['population', 'crime_rate_per_1000_people']
    scaler.fit(df[env_features])
    
    # Create SimpleImputer for missing values (only for environmental features)
    imputer = SimpleImputer(strategy='median')
    imputer.fit(df[env_features])
    
    # Load the exact one-hot encoded columns used during training
    
    ohe_path = os.path.join(base_dir, 'ohe_columns.pkl')
    with open(ohe_path, 'rb') as f:
        ohe_columns = pickle.load(f)
    
    return model, le, scaler, imputer, ohe_columns

def preprocess_input(raw_input, imputer, scaler, ohe_columns):
    df_raw = pd.DataFrame([raw_input])
    # Temporal transforms: include date components and cyclical time
    df_temp = df_raw[['year','month','day','hour','dayofweek']].copy()
    df_temp['hour_sin'] = np.sin(2*np.pi*df_temp['hour']/24)
    df_temp['hour_cos'] = np.cos(2*np.pi*df_temp['hour']/24)
    df_temp['dayofweek_sin'] = np.sin(2*np.pi*df_temp['dayofweek']/7)
    df_temp['dayofweek_cos'] = np.cos(2*np.pi*df_temp['dayofweek']/7)
    df_temp = df_temp.drop(['hour','dayofweek'], axis=1)
    
    # Spatial one-hot
    df_spat = pd.get_dummies(df_raw[['city','location_area']])
    df_spat = df_spat.reindex(columns=ohe_columns, fill_value=0)
    
    # Environmental features - apply imputer only to these
    df_env = df_raw[['population','crime_rate_per_1000_people']].copy()
    df_env_imputed = imputer.transform(df_env)
    
    # Combine into feature matrix
    X_full = np.hstack([df_spat.values, df_temp.values, df_env_imputed])
    
    # Split into three inputs
    s_dim = len(ohe_columns)
    t_dim = df_temp.shape[1]
    env_dim = df_env_imputed.shape[1]
    
    X_s = X_full[:, :s_dim]
    X_t = X_full[:, s_dim:s_dim + t_dim]
    X_e_raw = X_full[:, s_dim + t_dim : s_dim + t_dim + env_dim]
    X_e = scaler.transform(X_e_raw)
    return [X_t, X_s, X_e]

def predict_crime(raw_input, model, le, scaler, imputer, ohe_columns, top_k=5):
    # Use the actual TensorFlow Lite model for predictions - NO FALLBACKS
    if model is None:
        st.error("âŒ TensorFlow model not loaded. Cannot make predictions.")
        st.stop()
    
    # Preprocess the input
    X_inputs = preprocess_input(raw_input, imputer, scaler, ohe_columns)
    
    # Make prediction using TFLite model
    predictions = tflite_predict(model, X_inputs)
    
    # Get top-k predictions
    pred_probs = predictions[0]  # Assuming single sample
    top_indices = np.argsort(pred_probs)[::-1][:top_k]
    
    # Convert indices back to crime type names
    results = []
    for idx in top_indices:
        crime_type = le.inverse_transform([idx])[0]
        probability = float(pred_probs[idx])
        results.append((crime_type, probability))
    
    # Show model is working with REAL data
    st.sidebar.info(f"ğŸ§  Model processed {len(pred_probs)} crime types")
    st.sidebar.info(f"ğŸ“Š Max probability: {max(pred_probs):.3f}")
    st.sidebar.info(f"ğŸ¯ Input city: {raw_input.get('city', 'Unknown')}")
    st.sidebar.info(f"ğŸ• Input hour: {raw_input.get('hour', 'Unknown')}")
    
    return results

@st.cache_data
def load_data():
    try:
        # Load combined data from the streamlit directory
        base_dir = os.path.dirname(__file__)
        data_path = os.path.join(base_dir, 'combined_data.csv')
        return pd.read_csv(data_path)
    except Exception as e:
        st.error(f"Error loading data: {e}")
        return None

@st.cache_data
def get_unique_values():
    df = load_data()
    if df is not None:
        cities = sorted(df['city'].unique().tolist())
        areas = sorted(df['location_area'].unique().tolist())
        return cities, areas
    return [], []

# Streamlit UI
st.set_page_config(
    page_title="Connecticut Crime Prediction App",
    page_icon="ğŸš¨",
    layout="wide"
)

st.title("Connecticut Crime Prediction App")
st.markdown("---")

# Sidebar for navigation
st.sidebar.title("ğŸ” Navigation")
view = st.sidebar.radio("Select View", ["ğŸ”® Predict Crime", "ğŸ“Š Historical Analysis", "â„¹ï¸ About"])

# Load data and models
with st.spinner("Loading models and data..."):
    data = load_data()
    model, le, scaler, imputer, ohe_columns = load_artifacts()
    
    # Show model loading success
    if model is not None:
        st.sidebar.success("ğŸ¤– TensorFlow Lite Model Loaded!")
    else:
        st.sidebar.error("âŒ Model failed to load!")

if data is None or model is None:
    st.error("âŒ Failed to load required data or models. Please check file paths.")
    st.stop()

# Get unique values
cities, areas = get_unique_values()

if view == "ğŸ”® Predict Crime":
    st.header("Crime Prediction")
    st.markdown("Select parameters to predict the most likely crime type for a specific location and time.")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“ Location & Time")
        # Allow selecting multiple cities
        selected_cities = st.multiselect(
            "Select Cities",
            options=cities,
            default=cities[:1] if len(cities) >= 1 else cities,
            help="Choose one or more Connecticut cities for comparison"
        )
        area = st.selectbox("Location Area", areas, help="Select the type of location")
        
        # Time selection
        forecast_horizon = st.selectbox(
            "Forecast Horizon", 
            ["Next Day", "Next Week", "Next Month"],
            help="Choose the prediction timeframe"
        )
        
        # Calculate target datetime based on forecast horizon
        base_date = datetime.now()
        if forecast_horizon == "Next Day":
            target_date = base_date + timedelta(days=1)
        elif forecast_horizon == "Next Week":
            target_date = base_date + timedelta(weeks=1)
        else:  # Next Month
            target_date = base_date + timedelta(days=30)
            
        date = st.date_input("Target Date", target_date)
        
        # Time selection with hourly intervals
        hour = st.selectbox(
            "Target Hour", 
            options=list(range(0, 24)),
            index=target_date.hour,
            format_func=lambda x: f"{x:02d}:00",
            help="Select the hour (0-23)"
        )
        
    with col2:
        st.subheader("ğŸ™ï¸ Environmental Factors")
        
        # Get default values from the first selected city (fallback to first in list)
        fallback_city = selected_cities[0] if selected_cities else cities[0]
        city_data = data[data['city'] == fallback_city]
        default_pop = int(city_data['population'].iloc[0]) if not city_data.empty else 50000
        default_crime_rate = float(city_data['crime_rate_per_1000_people'].iloc[0]) if not city_data.empty else 100.0
        
        population = st.number_input(
            "Population", 
            min_value=1000, 
            max_value=200000, 
            value=default_pop,
            help="City population"
        )
        crime_rate = st.number_input(
            "Crime Rate per 1000 People", 
            min_value=0.0, 
            max_value=500.0, 
            value=default_crime_rate,
            step=0.1,
            help="Historical crime rate per 1000 residents"
        )

    # Trigger prediction and store in session state
    predict_clicked = st.button("ğŸ”® Predict Crime", type="primary", use_container_width=True)
    if predict_clicked:
        # Generate predictions for each city and cache
        dt = datetime.combine(date, datetime.min.time().replace(hour=hour))
        st.session_state['preds'] = {}
        for city in selected_cities:
            raw = {
                'city': city,
                'location_area': area,
                'year': dt.year,
                'month': dt.month,
                'day': dt.day,
                'hour': dt.hour,
                'dayofweek': dt.weekday(),
                'population': population,
                'crime_rate_per_1000_people': crime_rate
            }
            st.session_state['preds'][city] = predict_crime(raw, model, le, scaler, imputer, ohe_columns, top_k=10)
    # Display cached predictions with adjustable top_k
    if 'preds' in st.session_state:
        if selected_cities:
            tabs = st.tabs(selected_cities)
            for city, tab in zip(selected_cities, tabs):
                city_preds = st.session_state['preds'].get(city, [])
                with tab:
                    max_k = len(city_preds)
                    if max_k > 0:
                        n_top = st.slider(
                            "Number of top crime types to display",
                            min_value=1,
                            max_value=max_k,
                            value=min(5, max_k),
                            key=f"n_top_{city}"
                        )
                        preds = city_preds[:n_top]
                        results_df = pd.DataFrame(preds, columns=['Crime Type', 'Probability'])
                        st.markdown("---")
                        st.header(f"ğŸ¯ Predictions for {city}")
                        for idx, (crime, prob) in enumerate(preds, start=1):
                            st.write(f"**{idx}.** {crime}: {prob:.2%}")
                        fig = px.bar(
                            results_df, x='Probability', y='Crime Type', orientation='h',
                            color='Probability', color_continuous_scale='viridis', text='Probability'
                        )
                        fig.update_traces(texttemplate='%{text:.1%}', textposition='outside')
                        fig.update_layout(
                            xaxis_title='Probability',
                            xaxis=dict(tickformat='.1%'),
                            yaxis={'categoryorder':'total ascending'}, 
                            height=400, 
                            showlegend=False
                        )
                        st.plotly_chart(fig, use_container_width=True)
                        with st.expander("Show full predictions"):
                            st.dataframe(
                                results_df.assign(Probability=lambda df: df['Probability'].map(lambda x: f"{x:.2%}")),
                                use_container_width=True
                            )
                    else:
                        st.info("No predictions available for this city. Please check your input or try another city.")
        else:
            st.info("Please select at least one city to view predictions.")

elif view == "ğŸ“Š Historical Analysis":
    st.header("Historical Crime Analysis")
    st.markdown("Explore historical crime patterns in Connecticut cities.")
    
    # City selection for historical analysis
    selected_cities = st.multiselect("Select Cities", cities, default=cities[:5] if len(cities) >= 5 else cities)
    
    if selected_cities and not data.empty:
        # Filter data
        filtered_data = data[data['city'].isin(selected_cities)]
        
        # Time period selection
        years = sorted([int(year) for year in filtered_data['year'].unique()])  # Convert numpy.int64 to int
        if len(years) > 1:
            year_range = st.slider("Select Year Range", min_value=min(years), max_value=max(years), value=(min(years), max(years)))
            filtered_data = filtered_data[(filtered_data['year'] >= year_range[0]) & (filtered_data['year'] <= year_range[1])]
        
        if not filtered_data.empty:
            col1, col2 = st.columns(2)
            
            with col1:
                # Crime counts by city
                city_counts = filtered_data.groupby('city').size().reset_index(name='crime_count')
                fig1 = px.bar(city_counts, x='city', y='crime_count', title="Total Crimes by City")
                fig1.update_xaxes(tickangle=45)
                st.plotly_chart(fig1, use_container_width=True)
            
            with col2:
                # Crime types distribution
                crime_counts = filtered_data.groupby('offense_name').size().reset_index(name='count').head(10)
                fig2 = px.pie(crime_counts, values='count', names='offense_name', title="Top 10 Crime Types")
                st.plotly_chart(fig2, use_container_width=True)
            
            # Time series analysis
            monthly_crimes = filtered_data.groupby(['year', 'month']).size().reset_index(name='crime_count')
            monthly_crimes['date'] = pd.to_datetime(monthly_crimes[['year', 'month']].assign(day=1))
            
            fig3 = px.line(monthly_crimes, x='date', y='crime_count', title="Crime Trends Over Time")
            st.plotly_chart(fig3, use_container_width=True)
            
            # Location analysis
            location_counts = filtered_data.groupby('location_area').size().reset_index(name='count').head(15)
            fig4 = px.bar(location_counts, x='count', y='location_area', orientation='h', title="Crimes by Location Type")
            fig4.update_layout(yaxis={'categoryorder':'total ascending'})
            st.plotly_chart(fig4, use_container_width=True)
    
    else:
        st.info("Please select at least one city to view historical analysis.")

elif view == "â„¹ï¸ About":
    st.header("About This Application")
    st.markdown("""
    ### ğŸ¯ Purpose
    This Crime Prediction App uses machine learning to forecast the most likely crime types in Connecticut cities based on:
    - **Spatial features**: City and location type
    - **Temporal features**: Date, time, and day of the week  
    - **Environmental features**: Population and crime rate
    
    ### ğŸ§  Model Information
    - **Dense Neural Network**: DNN model trained on Connecticut crime data (2021-2023)
    - **Features**: 7 core features covering spatial, temporal, and environmental factors
    - **Output**: Probability distribution across 20 crime types
    
    ### ğŸ“Š Data Sources
    - Connecticut crime incidents from FBI Crime Database for the state of Connecticut
    - Years covered: 2021, 2022, 2023
    - Cities covered: 95 Connecticut municipalities
    
    ### ğŸš¨ Important Disclaimers
    - This tool is for **informational and research purposes only**
    - Predictions are based on historical patterns and may not reflect future events
    - Should **not be used as the sole basis** for law enforcement decisions
    - Crime is influenced by many factors not captured in this model
    
    ### ğŸ”§ Technical Details
    - Built with Streamlit, TensorFlow, and scikit-learn
    - Real-time predictions using pre-trained models
    - Interactive visualizations with Plotly
    """)
    
    # Model performance metrics (if available)
    st.subheader("ğŸ“ˆ Model Performance")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Training Data Size", "366K+ incidents")
    with col2:
        st.metric("Cities Covered", "95")
    with col3:
        st.metric("Crime Types", "20+")
